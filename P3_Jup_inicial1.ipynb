{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projeto 3 de Ciência dos Dados\n",
    "\n",
    "### Integrantes:\n",
    "\n",
    "\n",
    "Ana Clara Carneiro\n",
    "\n",
    "João Pedro Varella\n",
    "\n",
    "João Guilherme Almeida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "## Contextualização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pergunta:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A pergunta principal que será respondida no projeto é como diversos fatores influenciam na bilheteria de um filme. Como forma de estudo, estipularemos uma meta de bilheteria no decorrer das análises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sabe-se que anualmente, centenas de filmes entram em cartaz pelos diversos países do mundo. Dentre eles, a grande maioria não atinge altos valores de bilheteria. Por meio desse estudo, será possível compreender o que majoritariamente influencia se um filme será um sucesso ou se será um fracasso de bilheteria com as análises das diversas variáveis do Dataset. Dessa forma, torna-se possível compreender quais as melhores maneiras de se investir numa produção de cinema, a fim de maximizar o ganho em bilheteria. Esse estudo, enfim, possibilita a grandes produtoras compreender a melhor maneira de atingir altos valores de box office. Essas questões serão abordadas no andamento do projeto, para que, no fim, possamos responder à pergunta inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sobre o Dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dataset utilizado, entitulado \"The Movies Dataset\", extraído do Kaggle, reúne diversas informações sobre mais de 45 mil filmes. Dentre essas, pode-se citar: atores, diretores, produtores, orçamento, bilheteria, gênero, popularidade, faixa etária, etc. \n",
    "\n",
    "No entanto, filtrou-se algumas variáveis julgadas como mais relevantes para o intuito do estudo. Dessa forma, certas categorias foram dispensadas para o andamento das análises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O Dataset escolhido está disponível no link abaixo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/rounakbanik/the-movies-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos utilizados:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a realização do projeto foram utilizados os seguintes métodos de classificação: Random Forest, Regressão Logística e Máquina de Vetores de Suporte; para que fosse possível, no final do experimento, comparar os resultados obtidos e identificar qual deles gera a melhor acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro modelo a ser explicado será o de classificação do Random Forest. Este utiliza as variáveis de entrada do nosso Dataset, devolvendo, ao fim, uma variável de saída binária (no caso do nosso projeto, se o filme atinge ou não a meta estipulada). A forma pela qual esse método realiza essa análise é: Inicialmente, recebe um filme qualquer e verifica se o dado filme possui uma primeira variável de entrada (Tomemos a presença do ator Tom Hanks como exemplo) e em seguida, checa alguma outra variável de entrada (filme ser ou não de ação) e assim por diante, de forma que cada \"árvore\" devolverá uma variável binária para o filme atingir a meta, baseado nas respostas das variáveis de entrada. Após analisar todas as árvores, o Random Forest devolve uma variável de saída também na forma binária, se o filme conseguirá ou não bater a marca estabelecida, baseado nas respostas finais de cada árvore, gerando. Ao final, é gerado a precisão do modelo, o que torna possível definir se ele é realmente eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo modelo utilizado no estudo foi a Máquina de Vetores de Suporte. Este, assim como o método citado anteriormente, utiliza as variáveis de entrada selecionadas no DataSet para obter uma variável de saída binária no final de sua análise. Entretanto, os artifícos utilizados para realizar a classificação são divergentes. Este possuiu um algorítmo capaz de analisar os dados fornecidos e realizar uma série de suposições, as quais são utilizadas para definir os vetores suportes. Tais vetores são responsáveis por direcionar uma 'linha' extremamente precisa, a qual separa os dados em categorias. Dessa forma, com tal técnica é possível classificar com mais exatidão e, com isso, obter uma maior acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"movies_metadata.csv\")\n",
    "df2 = pd.read_csv(\"credits.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza do DataFrame \"Meta Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retirada dos JSONs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dataset utilizado, algumas variáveis estavam codificadas na forma de JSON. Para acessá-las, foi necessário extrair as informações e transformá-las em um dicionário. Nesta etapa da análise, extraímos os nomes dos atores de cada um dos filmes. Dessa forma, foi possível criar um dicionário relacionando duas variáveis, em que a chave corresponde ao nome do ator, e o valor dessa chave é o número de filmes em que cada ator atuou."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "atores = defaultdict(int)\n",
    "for e in df2.index:\n",
    "    data_dict = ast.literal_eval(df2[\"cast\"][e])\n",
    "    for palavras in data_dict:\n",
    "        nome = palavras['name']\n",
    "        \n",
    "        atores[nome] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Código para limpeza de certas variáveis tais como: revenue, budget, produtora e gênero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['revenue'] > 0]\n",
    "df_budget = df_0[df_0['budget'] != '0']\n",
    "df_clean = df_budget[df_budget['production_companies'] != '[]']\n",
    "df_super_clean = df_clean[df_clean['genres'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega_clean = df_super_clean[[\"id\",\"genres\",\"budget\",\"revenue\",\"production_companies\"]]\n",
    "df_mega_clean['budget'] = df_mega_clean['budget'].astype(float)\n",
    "df_mega_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análise Exploratória"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiramente foram analisadas as variáveis mais simplórias do DataFrame. Dessa forma, foram plotados histogramas que relacionam a frequência absoluta das variáveis Budget e Revenue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma da variável budget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega_clean.budget.plot.hist(density = False)\n",
    "plt.title('Budget')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pode-se observar pelo histograma acima que dentre os filmes disponibilizados no Dataset, a esmagadora maioria possui um baixo orçamento. Este fato explicita que os grandes filmes orçamentários representam somente uma pequena fatia de todos os filmes produzidos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograma da variável revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega_clean.revenue.plot.hist(density = False)\n",
    "plt.title('Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neste segundo histograma, que relaciona a bilheteria dos filmes, nota-se que, novamente, a esmagadora minoria atingiu altos valores nesse quesito. Isto demonstra que dentre todos os filmes anualmente chegam aos cinemas, poucos deles atingem um grande sucesso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráfico de dispersão das variáveis budget e revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Neste gráfico de dispersão, foram relacionadas as duas variáveis acima, de modo que fosse possível constatar a relação entre filmes com alto orçamento e filmes com alta bilheteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega_clean.plot.scatter(x=\"budget\", y = \"revenue\")\n",
    "plt.title('Budget x Revenue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de barras - Gêneros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A fim de disponibilizar os mais diversos filmes do Dataset relacionando-os por seus gêneros, criou-se um gráfico de barras em que cada coluna representa cada gênero presente nos dados. Dessa forma, pode-se concluir que os filmes de drama foram os mais presentes no Dataset escolhido, seguido pelos de comédia e de suspense, como pode ser observado no gráfico abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generos = []\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"genres\"][e])\n",
    "    for palavras in data_dict:\n",
    "        generos.append(palavras['name'])\n",
    "\n",
    "df_generos = pd.DataFrame(generos)\n",
    "df_generos\n",
    "geneross = df_generos[0].value_counts()\n",
    "geneross\n",
    "geneross.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot - Gêneros x Revenue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No entanto, para tornar mais visual a análise dos filmes por categoria relacionando com revenue, criou-se um box plot para cada uma delas. Para tal, foi necessário percorrer o dataset original e extrair o valor de bilheteria referente a cada filme; e, por fim, relacionar com cada categoria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues_por_categoria = {}\n",
    "categorias = [\n",
    "    'Drama', 'Comedy', 'Thriller',\n",
    "    'Action','Romance','Adventure','Crime','Science Fiction',\n",
    "    'Horror','Family','Fantasy','Mystery','Animation','History',\n",
    "    \"War\",'Music','Western','Documentary','Foreign','TV Movie'\n",
    "]\n",
    "\n",
    "for c in categorias:\n",
    "    revenues_por_categoria[c] = []\n",
    "\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"genres\"][e])\n",
    "    for palavras in data_dict:\n",
    "        cat = palavras[\"name\"]\n",
    "        if cat in revenues_por_categoria:\n",
    "            revenues_por_categoria[cat].append(df_mega_clean['revenue'][e])\n",
    "            \n",
    "for k in revenues_por_categoria:\n",
    "    revenues_por_categoria[k] = (np.array(revenues_por_categoria[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vale ressaltar que para a elaboração dos gráficos abaixo, foi necessário excluir os outliers de cada categoria, pois se estes fossem mantidos, impossibilitariam a visualização dos quartis e da média dos box plots, devido à grande disparidade de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(revenues_por_categoria.values(), showfliers=False)\n",
    "ax.set_xticklabels(revenues_por_categoria.keys(), rotation='vertical');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos de Barras - Produtoras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analogamente ao que foi feito para os gêneros, montou-se um gráfico de barras para que fosse possível observar quais produtoras mais realizaram filmes dentre as disponiblizadas pelo dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produtoras = []\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"production_companies\"][e])\n",
    "    for palavras in data_dict:\n",
    "        produtoras.append(palavras['name'])\n",
    "\n",
    "df_produtoras = pd.DataFrame(produtoras)\n",
    "df_produtoras\n",
    "produtorass = df_produtoras[0].value_counts().head(30)\n",
    "produtorass\n",
    "produtorass.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Box Plot - Produtoras x Revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenues_por_produtora = {}\n",
    "produtoras = [\n",
    "    'Warner Bros.','Universal Pictures','Paramount Pictures','Twentieth Century Fox Film Corporation','Columbia Pictures',\n",
    "    'New Line Cinema','Metro-Goldwyn-Mayer (MGM)','Touchstone Pictures','Walt Disney Pictures','Columbia Pictures Corporation',\n",
    "    'Relativity Media','United Artists','Miramax Films','TriStar Pictures','Canal+','Village Roadshow Pictures','DreamWorks SKG',\n",
    "    'Regency Enterprises','Lionsgate','Amblin Entertainment','Summit Entertainment','Dune Entertainment','Fox Searchlight Pictures',\n",
    "    'Dimension Films','Working Title Films','Fox 2000 Pictures','StudioCanal','Silver Pictures','Hollywood Pictures',\n",
    "    'The Weinstein Company'\n",
    "]\n",
    "\n",
    "for p in produtoras:\n",
    "    revenues_por_produtora[p] = []\n",
    "\n",
    "for f in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"production_companies\"][f])\n",
    "    for palavras in data_dict:\n",
    "        prod = palavras[\"name\"]\n",
    "        if prod in revenues_por_produtora:\n",
    "            revenues_por_produtora[prod].append(df_mega_clean['revenue'][f])\n",
    "        \n",
    "            \n",
    "for k in revenues_por_produtora:\n",
    "    revenues_por_produtora[k] = (np.array(revenues_por_produtora[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como foi feito para a série de box plots anterior, foi necessário retirar os dados dos outliers para que se tornasse possível observar os pontos importantes dos gráficos, tais como quartis e a média dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(revenues_por_produtora.values(), showfliers=False)\n",
    "ax.set_xticklabels(revenues_por_produtora.keys(), rotation='vertical');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza do DataFrame \"Credits\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_atores = pd.Series(atores)\n",
    "ser_atores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar de maneira mais ordenada e clara os dados do DataFrame, selecionamos a parcela de 0.1% de atores com mais produções no cinema. Dessa forma, atingimos todos com mais de 28 aparições:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_atores = ser_atores[ser_atores > 28].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para utilizar os dados do DataFrame acima no método do Random Forrest, foi necessário transformar as informações nele em um outro DataFrame com solução binária.\n",
    "\n",
    "Nesta nova tabela, cada linha representa cada um dos filmes contidos no database, e cada coluna representa os atores selecionados previamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filmes_atores = pd.DataFrame(index=df2.index, columns=ser_atores.index, dtype=np.uint8)\n",
    "for e in df2.index:\n",
    "    data_dict = ast.literal_eval(df2[\"cast\"][e])\n",
    "    for palavras in data_dict:\n",
    "        nome = palavras['name']\n",
    "        if nome in df_filmes_atores.columns:\n",
    "            df_filmes_atores[nome][e] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filmes_atores[df_filmes_atores != 1] = 0\n",
    "df_filmes_atores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se que neste DataFrame, a grande maioria dos dígitos é 0, o que representa o óbvio, os atores apareceram em poucos filmes em relação ao total estudado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset =\"original_title\", \n",
    "                     keep = 'first', inplace = True) \n",
    "df[\"original_title\"].value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bilhao'] = df.revenue > 1e9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza das variáveis de entrada tais como: revenue, budget, produtora e gênero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['revenue'] > 0]\n",
    "df_budget = df_0[df_0['budget'] != '0']\n",
    "df_clean = df_budget[df_budget['production_companies'] != '[]']\n",
    "df_super_clean = df_clean[df_clean['genres'] != '[]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_mega_clean = df_super_clean[[\"id\",\"genres\",\"budget\",\"revenue\",\"production_companies\"]]\n",
    "df_mega_clean['budget'] = df_mega_clean['budget'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mega_clean.revenue.quantile(0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula acima, verificou-se que o valor que corta os 20% das maiores bilheterias é 129 milhões de dólares, dessa forma, definimos que o valor que seria usado no modelo como meta de bilheteria para os filmes seria 150 milhões de dólares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milhao = []\n",
    "for dinheiro in df_mega_clean.revenue:\n",
    "    if dinheiro > 1.5e8:\n",
    "        milhao.append(1)\n",
    "    else:\n",
    "        milhao.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após definir a meta do modelo, percorremos todos os filmes e adicionamos uma nova coluna ao nosso dataframe original que indica se cada filme atingiu ou não atingiu os 150 milhões de dólares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mega_clean['Fez ou não 150 mi'] = milhao\n",
    "df_mega_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrando os atores por meio da limpeza estabelecida no DataFrame \"MetaData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_teste = []\n",
    "for numero in df_filmes_atores.index:\n",
    "    if numero not in df_mega_clean.id:\n",
    "        lista_teste.append(numero)\n",
    "        \n",
    "atores_certos = df_filmes_atores.drop(lista_teste, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No dataframe acima, foi selecionado os atores que participam dos filmes filtrados no Dataframe \"mega_clean\" fazendo com que agora podemos observar quais atores participaram dos filmes relevantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atores_certos['Fez ou não 150 mi'] = milhao\n",
    "atores_certos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_ou_nao = atores_certos['Fez ou não 150 mi']\n",
    "y = df_mega_clean['Fez ou não 150 mi']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Randon Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O próximo passo será nós rodarmos o Randon Forest com o nossos Datframes \"binários\" para que agora possamos verificar nosso objetivo que é verificar se de fato as feature que nós escolhemos impactam na bilheteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influência dos atores na bilheteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(atores_certos.drop(['Fez ou não 150 mi'],axis='columns'),sim_ou_nao,test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators = 40)\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que nossa acurácia é aproximadamente 80%, é possível afirmar que nosso classificador não é competente de classificar se um filme passará ou não da marca de 150 milhões de doláres se embasando apenas nos atores. Isso se dá pelo fato de apenas 20% dos filmes serem capazes de passar da nossa marca, portanto o nosso classificador não é capaz de ser melhor de um outro que julga como todos os filmes jamais passarão de 150 milhões."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influência das categorias na bilheteria "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorias2 = defaultdict(int)\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"genres\"][e])\n",
    "    for palavras in data_dict:\n",
    "        tipo = palavras['name']\n",
    "        categorias2[tipo] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_categorias = pd.Series(categorias2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filmes_categorias = pd.DataFrame(index=df_mega_clean.index, columns=ser_categorias.index, dtype=np.uint8)\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"genres\"][e])\n",
    "    #print(data_dict)\n",
    "    for palavras in data_dict:\n",
    "        tipo = palavras['name']\n",
    "        #print(tipo)\n",
    "        if tipo in df_filmes_categorias.columns:\n",
    "             df_filmes_categorias[tipo][e] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filmes_categorias[df_filmes_categorias != 1] = 0\n",
    "df_filmes_categorias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train, X2_test, Y2_train, Y2_test = train_test_split(df_filmes_categorias,sim_ou_nao,test_size = 0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 40)\n",
    "model.fit(X2_train,Y2_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X2_test,Y2_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pela mesma justificativa da relevância dos atores, podemos concluir que nosso classificador usando categorias de filme não não é capaz de dizer se um filme fará ou não 150 milhões de dólares na bilheteria. Isso se da pelo fato de a acurácia do classificador com \"categorias\" como variável de entrada ter dado, também, aproximadamente 80%. A diferença dos atores para as categorias de filme é apenas que a acurácia do segundo ter dado um pouco mais, ou seja, o segundo é um classificador mais preciso, o que indica que \"categorias de filmes\" é mais relevante pare dizer se um filme passará ou não da nossa marca"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influência das produtoras na bilheteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod2 = defaultdict(int)\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean['production_companies'][e])\n",
    "    for palavras in data_dict:\n",
    "        produ = palavras['name']\n",
    "        prod2[produ] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_produtora = pd.Series(prod2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filmes_produtoras = pd.DataFrame(index=df_mega_clean.index, columns=ser_produtora.index, dtype=np.uint8)\n",
    "for e in df_mega_clean.index:\n",
    "    data_dict = ast.literal_eval(df_mega_clean[\"production_companies\"][e])\n",
    "    #print(data_dict)\n",
    "    for palavras in data_dict:\n",
    "        produ = palavras['name']\n",
    "        #print(tipo)\n",
    "        if produ in df_filmes_produtoras.columns:\n",
    "             df_filmes_produtoras[produ][e] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_filmes_produtoras[df_filmes_produtoras != 1] = 0\n",
    "df_filmes_produtoras.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X3_train, X3_test, Y3_train, Y3_test = train_test_split(df_filmes_produtoras,sim_ou_nao,test_size = 0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 40)\n",
    "model.fit(X3_train,Y3_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X3_test,Y3_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pode-se afirmar que nosso classificador que recebe como variável de entrada \"produtoras de filmes\" não é muito bem sucedido. Isso se dá pelas mesmas justificativas expressas anteriormente, ou seja, como a acurácia deu aproxidamente 85%(próximo de 80), esse classificador não pode ser avaliado como um melhor que um classificador que julga que nenhum filme passará da marca de 150 milhões de dólares, já que a acurácia do segundo deveria ser 80, estando muito próximo da acurácia do primeiro. Dessa forma, um classificador ruim (que julga que nenhum filme passará de nossa marca) tem uma acurácia próxima à do nosso classificador, fazendo o segundo um classificador ruim também. Mesmo assim, até agora, a feature que possui maior relevância para nosso classificador, pode-se assumir que é \"produtoras de filmes\" já que essa deu a maior acurácia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influência do orçamento na bilheteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Bud = pd.DataFrame(df_mega_clean.budget)\n",
    "df_Bud.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X5_train, X5_test, Y5_train, Y5_test = train_test_split(df_Bud,sim_ou_nao,test_size = 0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 60)\n",
    "model.fit(X5_train,Y5_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X5_test,Y5_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(zip(model.feature_importances_, X5_test.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, nossa classificador que utiliza como variável de entrada \"orçamento\" também não pode ser expresso como classificador bom. Isso pois, este apresenta uma acurácia de aproximadamente 87%, de novo, próximo à 80%, fazendo com que este tenha uma acurácia tão boa quanto um classificador ruim que julga que nenhum filme passa da marca de 150 milhões de dólares. Porém, esse classificador indica que a feature \"orçamento\" é a mais relevante dentre todas nossas features, já que este apresenta a maior acurácia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultados finais para comparação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_forest = pd.concat([\n",
    "    df_filmes_categorias,\n",
    "    atores_certos.drop(['Fez ou não 150 mi'],axis='columns'),\n",
    "    df_filmes_produtoras,\n",
    "    df_mega_clean.budget,\n",
    "\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X4_train, X4_test, Y4_train, Y4_test = train_test_split(df_forest,sim_ou_nao,test_size = 0.3)\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 60)\n",
    "model.fit(X4_train,Y4_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.score(X4_test,Y4_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sorted(list(zip(model.feature_importances_, X4_test.columns)), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X4_train,Y4_train)\n",
    "Ypred = model.predict(X4_test)\n",
    "print(accuracy_score(Y4_test,Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Máquina de vetores de suporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()\n",
    "model.fit(X4_train,Y4_train)\n",
    "Ypred = model.predict(X4_test)\n",
    "print(accuracy_score(Y4_test,Ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portanto, pode-se concluir nesse projeto que não foi possível criar um classificador competente de dizer com certeza se um filme conseguirá ou não passar da marca de 150 milhões de dólares. Isso pode ser dito porque mesmo quando o classificador reagrupa todas as features utilizadas (atores, produtoras, orçamento e categorias de filmes), ele não é capaz de expressar se um filme arrecadará o valor escolhido, dado que a acurácia desse deu menor que 90% em todos os tipos de classificadores. O fato de a precisão ser menor que 90% indica que o classificador não é bom porque apenas 20% dos filmes do nosso dataset conseguiram arrecadar 150 milhões de dólares, ou seja se um classificador que julga que nenhum filme consegue passar dessa marca, ele vai ter 80% de acurácia. Logo, este classificador é quase tão preciso quanto o feito nesse projeto, porém a diferença entre ambos é que o do projeto é capaz de dizer se alguns filmes (menos de 50% dos 20% do nosso dataframe) são capazes de passar de 150 milhões de dólares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Não é possível afirmar com certeza quais fatores podem aprimorar nosso classificador. Porém pode-se estipular que adicionar mais features podem fazer com que nosso classificador tenha uma maior precisão e confiabilidade, já que ele vai ser capaz de reagrupar mais informações e mais bases para dizer o que faz com que um filme consiga ou não passar da marca de 150 milhões de dólares. Essas features podem ser \"faixa etária\", \"período no qual o filme foi lançado\" e etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota-se também que no modelo de Random Forest, a feature mais importante para dizer se um filme consegue passar ou não da marca expressa no projeto é \"budget\" (orçamento), o que faz sentido já que notamos que o classificador que utiliza apenas \"budget\" como variável de entrada atingiu maior acurácia, concluindo assim que de fato esta é a feature mais importante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por fim, vale a pena ressaltar que a diferença da acurácia entre os diferente métodos de classificação é dada já que cada um desses métodos leva em conta diferentes valores. Pode-se estipular, portanto, que o método de Random Forest foi o que teve maior acurácia, porque esse foi capaz de escolher quais eram as variáveis mais relevantes para julgar se um filme conseguirá passar da marca, já o método de Regressão Logística teve uma menor acurácia por ele justamente não ser capaz de escolher as melhores e mais importantes features para classificar os filmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
